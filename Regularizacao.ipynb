{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularização L1 L2 VS Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressão com o dataset MPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desativa os warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o dataset\n",
    "dataset = pd.read_csv('data-mpg/auto-mpg.csv', na_values=['NA', '?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpg             0\n",
       "cylinders       0\n",
       "displacement    0\n",
       "horsepower      6\n",
       "weight          0\n",
       "acceleration    0\n",
       "year            0\n",
       "origin          0\n",
       "name            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando a quantidade de valores nulos no dataset\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  year  \\\n",
       "0  18.0          8         307.0       130.0    3504          12.0    70   \n",
       "1  15.0          8         350.0       165.0    3693          11.5    70   \n",
       "2  18.0          8         318.0       150.0    3436          11.0    70   \n",
       "3  16.0          8         304.0       150.0    3433          12.0    70   \n",
       "4  17.0          8         302.0       140.0    3449          10.5    70   \n",
       "\n",
       "   origin                       name  \n",
       "0       1  chevrolet chevelle malibu  \n",
       "1       1          buick skylark 320  \n",
       "2       1         plymouth satellite  \n",
       "3       1              amc rebel sst  \n",
       "4       1                ford torino  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exibindo os dados\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções auxiliares\n",
    "\n",
    "# Converte todos os valores faltantes na coluna especificada para a mediana\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "\n",
    "# Converte um dataframe Pandas para as entradas x, y que o TensorFlow precisa\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # Descobre o tipo da coluna de destino. \n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(target_type, '__iter__') else target_type\n",
    "    # Encoding para int. TensorFlow gosta de 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classificação\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].to_numpy(dtype=np.float32), dummies.to_numpy(dtype=np.float32)\n",
    "    else:\n",
    "        # Regressão\n",
    "        return df[result].to_numpy(dtype=np.float32), df[target].to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-processamento\n",
    "dataset.drop('name', 1, inplace = True)\n",
    "missing_median(dataset, 'horsepower')\n",
    "X, Y = to_xy(dataset, 'mpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo os dados de treino e validação\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(X, Y, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train:  (298, 7)\n",
      "X validation (100, 7)\n",
      "Y train:  (298,)\n",
      "Y validation:  (100,)\n"
     ]
    }
   ],
   "source": [
    "# Shape dos dados de treino e validação\n",
    "print(\"X train: \", x_train.shape)\n",
    "print(\"X validation\", x_validation.shape)\n",
    "print(\"Y train: \", y_train.shape)\n",
    "print(\"Y validation: \", y_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construindo o modelo\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(input_dim = x_train.shape[1],\n",
    "                 units = 128,\n",
    "                 kernel_initializer = 'normal',\n",
    "                 activation = 'relu'))\n",
    "\n",
    "model1.add(Dense(input_dim = 128,\n",
    "                 units = 64,\n",
    "                 kernel_initializer = 'normal',\n",
    "                 activation = 'relu'))\n",
    "\n",
    "model1.add(Dense(input_dim = 64, \n",
    "                 units = 10,\n",
    "                 kernel_initializer = 'normal',\n",
    "                 activation = 'relu',\n",
    "                 kernel_regularizer = regularizers.l2(0.01),\n",
    "                 activity_regularizer = regularizers.l1(0.01)))\n",
    "\n",
    "model1.add(Dense(input_dim = 64,\n",
    "                 units = 1,\n",
    "                 kernel_initializer = 'normal'))\n",
    "\n",
    "model1.compile(loss = 'mean_squared_error', optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               1024      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 9,941\n",
      "Trainable params: 9,941\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Verificando a arquitetura da rede\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo as callbacks\n",
    "monitor = EarlyStopping(monitor = 'val_loss', min_delta = 0.001, patience = 10, verbose = 3, mode = 'auto')\n",
    "\n",
    "plateau = ReduceLROnPlateau(monitor = 'loss',\n",
    "                            factor = 0.01,\n",
    "                            patience = 5,\n",
    "                            mode = 'min',\n",
    "                            min_lr = 0.000001,\n",
    "                            verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
      "Wall time: 7.15 µs\n",
      "Epoch 1/1000\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 481.0553 - val_loss: 349.7662 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 285.6888 - val_loss: 184.5218 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 195.8353 - val_loss: 194.4182 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 233.1296 - val_loss: 175.5418 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 188.1895 - val_loss: 175.4168 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 197.0308 - val_loss: 189.2932 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 200.1477 - val_loss: 176.0066 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 188.8386 - val_loss: 165.4679 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 191.1779 - val_loss: 165.5765 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 188.0835 - val_loss: 165.5731 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 185.5583 - val_loss: 167.8678 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 185.1979 - val_loss: 163.7462 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 183.2818 - val_loss: 161.7089 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 182.5652 - val_loss: 161.4958 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 181.3856 - val_loss: 160.7582 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 180.2527 - val_loss: 158.8685 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 179.0777 - val_loss: 158.7336 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 177.8123 - val_loss: 156.6648 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 176.3211 - val_loss: 155.6870 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 174.7723 - val_loss: 155.7912 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 174.4073 - val_loss: 152.3574 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 171.3351 - val_loss: 151.8788 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 170.4098 - val_loss: 150.4615 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 167.3845 - val_loss: 146.1896 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 165.6645 - val_loss: 144.3086 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 162.9501 - val_loss: 143.8757 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 160.5016 - val_loss: 138.5475 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 156.6237 - val_loss: 137.3699 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 152.4420 - val_loss: 131.7029 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 147.8423 - val_loss: 127.7664 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 142.6223 - val_loss: 122.0748 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 135.9144 - val_loss: 117.9098 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 129.9655 - val_loss: 110.4979 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 122.8696 - val_loss: 102.2762 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 111.3436 - val_loss: 97.4590 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 102.2865 - val_loss: 84.7523 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 92.2948 - val_loss: 76.4001 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 79.1849 - val_loss: 66.3318 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 66.8205 - val_loss: 60.1041 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 57.2040 - val_loss: 53.7600 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 49.4575 - val_loss: 51.0904 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 42.6396 - val_loss: 48.6064 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 38.4857 - val_loss: 46.0786 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 36.0852 - val_loss: 44.8785 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.6325 - val_loss: 44.6703 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 33.0128 - val_loss: 53.0965 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 36.4300 - val_loss: 49.4038 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 33.8536 - val_loss: 50.2393 - lr: 0.0010\n",
      "Epoch 49/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 33.0885 - val_loss: 43.0315 - lr: 0.0010\n",
      "Epoch 50/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 29.2770 - val_loss: 42.7170 - lr: 0.0010\n",
      "Epoch 51/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 28.1748 - val_loss: 43.1329 - lr: 0.0010\n",
      "Epoch 52/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 27.6608 - val_loss: 41.6752 - lr: 0.0010\n",
      "Epoch 53/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 26.9944 - val_loss: 42.4500 - lr: 0.0010\n",
      "Epoch 54/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 26.7835 - val_loss: 40.3132 - lr: 0.0010\n",
      "Epoch 55/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 27.1052 - val_loss: 40.0335 - lr: 0.0010\n",
      "Epoch 56/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 26.3118 - val_loss: 40.0796 - lr: 0.0010\n",
      "Epoch 57/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 24.9993 - val_loss: 38.4624 - lr: 0.0010\n",
      "Epoch 58/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 24.9548 - val_loss: 40.8367 - lr: 0.0010\n",
      "Epoch 59/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 25.3178 - val_loss: 39.0135 - lr: 0.0010\n",
      "Epoch 60/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 24.5389 - val_loss: 39.3951 - lr: 0.0010\n",
      "Epoch 61/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 23.9563 - val_loss: 40.0244 - lr: 0.0010\n",
      "Epoch 62/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 25.3323 - val_loss: 36.7739 - lr: 0.0010\n",
      "Epoch 63/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 23.9904 - val_loss: 36.4960 - lr: 0.0010\n",
      "Epoch 64/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 23.0585 - val_loss: 39.8316 - lr: 0.0010\n",
      "Epoch 65/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 22.1546 - val_loss: 36.6024 - lr: 0.0010\n",
      "Epoch 66/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.8622 - val_loss: 35.8312 - lr: 0.0010\n",
      "Epoch 67/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 21.7284 - val_loss: 39.9893 - lr: 0.0010\n",
      "Epoch 68/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 22.0930 - val_loss: 35.0426 - lr: 0.0010\n",
      "Epoch 69/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 21.3168 - val_loss: 34.8528 - lr: 0.0010\n",
      "Epoch 70/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 20.9141 - val_loss: 35.6297 - lr: 0.0010\n",
      "Epoch 71/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 10ms/step - loss: 20.4119 - val_loss: 36.2033 - lr: 0.0010\n",
      "Epoch 72/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 20.0830 - val_loss: 34.7824 - lr: 0.0010\n",
      "Epoch 73/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 19.4203 - val_loss: 34.8455 - lr: 0.0010\n",
      "Epoch 74/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 19.1709 - val_loss: 34.5965 - lr: 0.0010\n",
      "Epoch 75/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 19.1958 - val_loss: 33.1070 - lr: 0.0010\n",
      "Epoch 76/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 19.1455 - val_loss: 32.9656 - lr: 0.0010\n",
      "Epoch 77/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 18.9979 - val_loss: 36.7985 - lr: 0.0010\n",
      "Epoch 78/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 19.1696 - val_loss: 33.8108 - lr: 0.0010\n",
      "Epoch 79/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 18.6023 - val_loss: 32.4189 - lr: 0.0010\n",
      "Epoch 80/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 19.3949 - val_loss: 33.2509 - lr: 0.0010\n",
      "Epoch 81/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 18.0079 - val_loss: 32.9054 - lr: 0.0010\n",
      "Epoch 82/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 17.5871 - val_loss: 32.6865 - lr: 0.0010\n",
      "Epoch 83/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 17.8626 - val_loss: 31.5523 - lr: 0.0010\n",
      "Epoch 84/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 17.2510 - val_loss: 31.6522 - lr: 0.0010\n",
      "Epoch 85/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 16.9960 - val_loss: 32.2431 - lr: 0.0010\n",
      "Epoch 86/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 17.3301 - val_loss: 30.0439 - lr: 0.0010\n",
      "Epoch 87/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 16.8033 - val_loss: 30.4880 - lr: 0.0010\n",
      "Epoch 88/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 17.0198 - val_loss: 35.6030 - lr: 0.0010\n",
      "Epoch 89/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 18.5355 - val_loss: 30.3331 - lr: 0.0010\n",
      "Epoch 90/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 17.5492 - val_loss: 29.2341 - lr: 0.0010\n",
      "Epoch 91/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 16.6476 - val_loss: 30.9071 - lr: 0.0010\n",
      "Epoch 92/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 16.3621 - val_loss: 29.1890 - lr: 0.0010\n",
      "Epoch 93/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 16.0954 - val_loss: 28.3680 - lr: 0.0010\n",
      "Epoch 94/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 17.1717 - val_loss: 30.2875 - lr: 0.0010\n",
      "Epoch 95/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 16.1473 - val_loss: 30.9067 - lr: 0.0010\n",
      "Epoch 96/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 15.4589 - val_loss: 28.0751 - lr: 0.0010\n",
      "Epoch 97/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 15.7585 - val_loss: 27.4201 - lr: 0.0010\n",
      "Epoch 98/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 15.9205 - val_loss: 27.8702 - lr: 0.0010\n",
      "Epoch 99/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 14.9599 - val_loss: 28.0253 - lr: 0.0010\n",
      "Epoch 100/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15.1193 - val_loss: 31.2642 - lr: 0.0010\n",
      "Epoch 101/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 15.7973 - val_loss: 27.3017 - lr: 0.0010\n",
      "Epoch 102/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14.9106 - val_loss: 26.6786 - lr: 0.0010\n",
      "Epoch 103/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 14.4106 - val_loss: 27.5177 - lr: 0.0010\n",
      "Epoch 104/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 14.1427 - val_loss: 27.2873 - lr: 0.0010\n",
      "Epoch 105/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 13.9698 - val_loss: 26.3251 - lr: 0.0010\n",
      "Epoch 106/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 13.7587 - val_loss: 25.5287 - lr: 0.0010\n",
      "Epoch 107/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 13.7249 - val_loss: 25.5948 - lr: 0.0010\n",
      "Epoch 108/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 14.0835 - val_loss: 27.1625 - lr: 0.0010\n",
      "Epoch 109/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 13.4803 - val_loss: 27.2436 - lr: 0.0010\n",
      "Epoch 110/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 13.5256 - val_loss: 25.2808 - lr: 0.0010\n",
      "Epoch 111/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 13.2080 - val_loss: 24.3900 - lr: 0.0010\n",
      "Epoch 112/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 13.8407 - val_loss: 25.1685 - lr: 0.0010\n",
      "Epoch 113/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 15.0702 - val_loss: 29.3182 - lr: 0.0010\n",
      "Epoch 114/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 14.6224 - val_loss: 29.1266 - lr: 0.0010\n",
      "Epoch 115/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 14.1640 - val_loss: 25.4013 - lr: 0.0010\n",
      "Epoch 116/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 13.7227\n",
      "Epoch 00116: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 14.3341 - val_loss: 25.4808 - lr: 0.0010\n",
      "Epoch 117/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 16.4590 - val_loss: 24.8563 - lr: 1.0000e-05\n",
      "Epoch 118/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 15.2978 - val_loss: 24.0109 - lr: 1.0000e-05\n",
      "Epoch 119/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 14.0598 - val_loss: 23.4219 - lr: 1.0000e-05\n",
      "Epoch 120/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 12.9818 - val_loss: 23.2794 - lr: 1.0000e-05\n",
      "Epoch 121/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 12.5198 - val_loss: 23.4404 - lr: 1.0000e-05\n",
      "Epoch 122/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 12.2791 - val_loss: 23.7033 - lr: 1.0000e-05\n",
      "Epoch 123/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 12.2986 - val_loss: 23.9539 - lr: 1.0000e-05\n",
      "Epoch 124/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 12.3168 - val_loss: 24.0609 - lr: 1.0000e-05\n",
      "Epoch 125/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 12.3401 - val_loss: 24.0901 - lr: 1.0000e-05\n",
      "Epoch 126/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 12.3365 - val_loss: 24.0294 - lr: 1.0000e-05\n",
      "Epoch 127/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 14.0949\n",
      "Epoch 00127: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 12.3063 - val_loss: 23.9733 - lr: 1.0000e-05\n",
      "Epoch 128/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 12.2962 - val_loss: 23.9649 - lr: 1.0000e-06\n",
      "Epoch 129/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 12.2954 - val_loss: 23.9526 - lr: 1.0000e-06\n",
      "Epoch 130/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 12.2913 - val_loss: 23.9454 - lr: 1.0000e-06\n",
      "Epoch 00130: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9740372250>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "# Treinando o modelo\n",
    "\n",
    "model1.fit(x_train,\n",
    "           y_train,\n",
    "           validation_data=(x_validation, y_validation),\n",
    "           callbacks = [monitor, plateau],\n",
    "           batch_size = 64,\n",
    "           epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSME:  4.627955\n"
     ]
    }
   ],
   "source": [
    "# Fazendo as previsões\n",
    "pred1 = model1.predict(x_validation)\n",
    "\n",
    "# Cálcula o RSME (Root square mean error )\n",
    "rmse = np.sqrt(metrics.mean_squared_error(pred1, y_validation))\n",
    "\n",
    "# Exibe o rmse\n",
    "print(\"RSME: \", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construindo o modelo\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(input_dim = x_train.shape[1],\n",
    "                 units = 128,\n",
    "                 kernel_initializer = 'normal',\n",
    "                 activation = 'relu'))\n",
    "\n",
    "model2.add(Dense(input_dim = 128,\n",
    "                 units = 64,\n",
    "                 kernel_initializer = 'normal',\n",
    "                activation = 'relu'))\n",
    "\n",
    "model2.add(Dropout(0.25))\n",
    "\n",
    "model2.add(Dense(input_dim = 64, \n",
    "                 units = 10,\n",
    "                 kernel_initializer = 'normal',\n",
    "                 activation = 'relu'))\n",
    "\n",
    "model2.add(Dense(input_dim = 64,\n",
    "                 units = 1,\n",
    "                 kernel_initializer = 'normal'))\n",
    "\n",
    "model2.compile(loss = 'mean_squared_error', optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 128)               1024      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 9,941\n",
      "Trainable params: 9,941\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Exibindo a arquitetura do modelo\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 569.7275 - val_loss: 453.0809 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 393.0148 - val_loss: 286.2719 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 244.0111 - val_loss: 166.9273 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 205.0907 - val_loss: 181.2050 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 223.9027 - val_loss: 163.4240 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 199.9027 - val_loss: 177.5143 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 200.0428 - val_loss: 184.6081 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 195.8173 - val_loss: 172.9558 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 194.8932 - val_loss: 161.9240 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 190.3723 - val_loss: 158.9900 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 194.4597 - val_loss: 158.7255 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 187.9994 - val_loss: 161.4182 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 190.3676 - val_loss: 162.6231 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 182.9719 - val_loss: 159.4444 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 184.3742 - val_loss: 155.5172 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 186.3266 - val_loss: 154.2249 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 177.9116 - val_loss: 155.3077 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 180.3842 - val_loss: 152.2274 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 180.9022 - val_loss: 150.2907 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 181.1647 - val_loss: 150.0913 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 175.0762 - val_loss: 146.5641 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 174.3765 - val_loss: 144.8967 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 170.8032 - val_loss: 140.3161 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 167.1363 - val_loss: 138.5463 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 155.6495 - val_loss: 132.4009 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 157.4384 - val_loss: 127.3883 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 151.1016 - val_loss: 123.4871 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 141.1507 - val_loss: 114.5317 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 136.1144 - val_loss: 109.2324 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 131.3926 - val_loss: 103.2785 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 119.7327 - val_loss: 91.7183 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 108.0398 - val_loss: 82.7454 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 95.2477 - val_loss: 72.2551 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 92.1706 - val_loss: 64.5750 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 84.4000 - val_loss: 58.9557 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 73.2868 - val_loss: 52.6074 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 66.5677 - val_loss: 53.5309 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 64.2421 - val_loss: 49.5677 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 59.5438 - val_loss: 51.3716 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 51.4290 - val_loss: 49.2703 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 55.7534 - val_loss: 56.4498 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 54.0608 - val_loss: 45.9610 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 46.5567 - val_loss: 44.1838 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 47.2469 - val_loss: 43.7199 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 47.6269 - val_loss: 44.1151 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 45.1217 - val_loss: 43.0424 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 41.8911 - val_loss: 43.2988 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 41.6318 - val_loss: 41.7317 - lr: 0.0010\n",
      "Epoch 49/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 38.4059 - val_loss: 41.5796 - lr: 0.0010\n",
      "Epoch 50/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 41.7376 - val_loss: 42.6374 - lr: 0.0010\n",
      "Epoch 51/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 39.6152 - val_loss: 42.7750 - lr: 0.0010\n",
      "Epoch 52/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 39.6630 - val_loss: 41.5142 - lr: 0.0010\n",
      "Epoch 53/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 37.3481 - val_loss: 40.3978 - lr: 0.0010\n",
      "Epoch 54/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 36.8599 - val_loss: 40.2110 - lr: 0.0010\n",
      "Epoch 55/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 37.5847 - val_loss: 42.9162 - lr: 0.0010\n",
      "Epoch 56/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 37.4660 - val_loss: 49.4227 - lr: 0.0010\n",
      "Epoch 57/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 36.7772 - val_loss: 42.9222 - lr: 0.0010\n",
      "Epoch 58/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 37.6433 - val_loss: 40.4738 - lr: 0.0010\n",
      "Epoch 59/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 35.8994 - val_loss: 36.6971 - lr: 0.0010\n",
      "Epoch 60/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 36.4797 - val_loss: 37.0746 - lr: 0.0010\n",
      "Epoch 61/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 33.3011 - val_loss: 38.0204 - lr: 0.0010\n",
      "Epoch 62/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 36.5673 - val_loss: 37.3625 - lr: 0.0010\n",
      "Epoch 63/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 32.4708 - val_loss: 38.8290 - lr: 0.0010\n",
      "Epoch 64/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 38.3665 - val_loss: 37.9301 - lr: 0.0010\n",
      "Epoch 65/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 34.5781 - val_loss: 38.9492 - lr: 0.0010\n",
      "Epoch 66/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 35.4673 - val_loss: 37.5347 - lr: 0.0010\n",
      "Epoch 67/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 35.3355 - val_loss: 37.1444 - lr: 0.0010\n",
      "Epoch 68/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 32.4281 - val_loss: 36.8208 - lr: 0.0010\n",
      "Epoch 69/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 29.4237 - val_loss: 35.9674 - lr: 0.0010\n",
      "Epoch 70/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 29.7330 - val_loss: 34.5546 - lr: 0.0010\n",
      "Epoch 71/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.0519 - val_loss: 34.8717 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 27.6934 - val_loss: 35.6347 - lr: 0.0010\n",
      "Epoch 73/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 30.6068 - val_loss: 34.1787 - lr: 0.0010\n",
      "Epoch 74/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 29.7984 - val_loss: 32.9254 - lr: 0.0010\n",
      "Epoch 75/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 28.3881 - val_loss: 32.9264 - lr: 0.0010\n",
      "Epoch 76/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 28.4499 - val_loss: 34.4063 - lr: 0.0010\n",
      "Epoch 77/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 20.7489\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 30.9099 - val_loss: 35.8365 - lr: 0.0010\n",
      "Epoch 78/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 30.5308 - val_loss: 35.7161 - lr: 1.0000e-05\n",
      "Epoch 79/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 29.8143 - val_loss: 35.2763 - lr: 1.0000e-05\n",
      "Epoch 80/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 27.6849 - val_loss: 34.7148 - lr: 1.0000e-05\n",
      "Epoch 81/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 26.1343 - val_loss: 34.2344 - lr: 1.0000e-05\n",
      "Epoch 82/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 30.3259 - val_loss: 33.8748 - lr: 1.0000e-05\n",
      "Epoch 83/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 24.8583 - val_loss: 33.6281 - lr: 1.0000e-05\n",
      "Epoch 84/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 25.8814 - val_loss: 33.4847 - lr: 1.0000e-05\n",
      "Epoch 00084: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f972c130250>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treinando o modelo\n",
    "model2.fit(x_train,\n",
    "           y_train,\n",
    "           validation_data = (x_validation, y_validation),\n",
    "           callbacks = [monitor, plateau],\n",
    "           batch_size = 64,\n",
    "           epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSME:  5.7865973\n"
     ]
    }
   ],
   "source": [
    "# Fazendo as previsões\n",
    "pred2 = model2.predict(x_validation)\n",
    "\n",
    "# Cálcula o RSME (Root square mean error )\n",
    "rmse = np.sqrt(metrics.mean_squared_error(pred2, y_validation))\n",
    "\n",
    "# Exibe o rmse\n",
    "print(\"RSME: \", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "O modelo treinado utilizando a técnica de regularização L1 L2 teve melhor resultado quando comparado ao modelo treinado utilizando a técnica de regularização Dropout, porém, o modelo tomou mais épocas e consequentemente mais tempo do que com Dropout."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
